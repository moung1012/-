{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "_6 경사하강법(Gradient Decent)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moung1012/deeplearning-study/blob/main/_6_%EA%B2%BD%EC%82%AC%ED%95%98%EA%B0%95%EB%B2%95(Gradient_Decent).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eGZ0TCq_yf5"
      },
      "source": [
        "## 경사하강법(Gradient Decent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixzUUedJVFHF"
      },
      "source": [
        "### 볼록함수(Convex Function)\n",
        "- 어떤 지점에서 시작하더라도 최적값(손실함수가 최소로하는 점)에 도달할 수 있음\n",
        "\n",
        "- 1-D Convex Function\n",
        "![](https://www.researchgate.net/profile/Miodrag_Mateljevic/publication/313821095/figure/fig5/AS:476113622310916@1490525741603/A-strictly-convex-function.png)\n",
        "<br /><sub>출처: https://www.researchgate.net/figure/A-strictly-convex-function_fig5_313821095</sub>\n",
        "\n",
        "- 2-D Convex Function  \n",
        "![](https://www.researchgate.net/publication/275069197/figure/fig8/AS:324418665500689@1454358845613/Sphere-function-D-2.png)\n",
        "<br /><sub>출처: https://www.researchgate.net/figure/Sphere-function-D-2_fig8_275069197</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVo4WnbtRiUM"
      },
      "source": [
        "### 비볼록함수(Non-Convex Function)\n",
        "\n",
        "- 비볼록 함수는 시작점 위치에 따라 다른 최적값에 도달할 수 있음.\n",
        "\n",
        "- 1-D Non-Convex Function\n",
        "![](https://image1.slideserve.com/2659452/example-of-non-convex-function-l.jpg)\n",
        "\n",
        "<sub>출처: https://www.slideserve.com/betha/local-and-global-optima</sub>\n",
        "\n",
        "- 2-D Non-Convex Function\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/e/e3/Non-Convex_Objective_Function.gif)\n",
        "\n",
        "<sub>출처: https://commons.wikimedia.org/wiki/File:Non-Convex_Objective_Function.gif</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1u8PzsUVMBZ"
      },
      "source": [
        "### 경사하강법\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMXY9TYKTa4P"
      },
      "source": [
        "#### 미분과 기울기\n",
        "- 스칼라를 벡터로 미분한 것\n",
        "\n",
        "## $\\quad \\frac{df(x)}{dx} = \\lim_{\\triangle x \\to 0} \\frac{f(x+\\triangle x) - f(x)}{\\triangle x}$\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Gradient2.svg/2560px-Gradient2.svg.png)\n",
        "\n",
        "<sub>출처: https://ko.wikipedia.org/wiki/%EA%B8%B0%EC%9A%B8%EA%B8%B0_(%EB%B2%A1%ED%84%B0)</sub>\n",
        "\n",
        "  ## $\\quad \\triangledown f(x) = \\left( \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2},\\ ... \\ , \\frac{\\partial f}{\\partial x_N} \\right)$\n",
        "  - 변화가 있는 지점에서는 미분값이 존재하고, 변화가 없는 지점은 미분값이 0\n",
        "  - 미분값이 클수록 변화량이 크다는 의미\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmZo4rLNTccp"
      },
      "source": [
        "#### 경사하강법의 과정\n",
        "\n",
        "- 경사하강법은 한 스텝마다의 미분값에 따라 이동하는 방향을 결정\n",
        "\n",
        "- $f(x)$의 값이 변하지 않을 때까지 반복\n",
        "\n",
        "  ## $\\qquad x_n = x_{n-1} - \\eta \\frac{\\partial f}{\\partial x}$\n",
        "    \n",
        "    - $\\eta$ : 학습률(learning rate)\n",
        "\n",
        "- 즉, **미분값이 0인 지점**을 찾는 방법  \n",
        "\n",
        "![](https://cdn-images-1.medium.com/max/1600/0*fU8XFt-NCMZGAWND.)\n",
        "<br /><sub>출처: https://www.kdnuggets.com/2018/06/intuitive-introduction-gradient-descent.html</sub>\n",
        "\n",
        "\n",
        "- 2-D 경사하강법\n",
        "\n",
        "![](https://thumbs.gfycat.com/AngryInconsequentialDiplodocus-size_restricted.gif)\n",
        "<br /><sub>출처: https://gfycat.com/ko/angryinconsequentialdiplodocus</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsK-9-3cEphu"
      },
      "source": [
        "#### 경사하강법 구현\n",
        "\n",
        "$\\quad f_1(x) = x^2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CUGyiQMEsAD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzTrK1gcEr6g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEicOhyGE48y"
      },
      "source": [
        "#### 경사하강법 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8sIzMtlEr33"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaVWMFoEFAPJ"
      },
      "source": [
        "#### 비볼록 함수(Non-Convex Function)에서의 경사하강법\n",
        "\n",
        "$\\quad f_2(x) = 0.01x^4 - 0.3x^3 - 1.0x + 10.0$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLcnM77vEr2K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPCibdNFFLzm"
      },
      "source": [
        "#### 비볼록함수 경사하강법 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IJDWUno9Tpu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyrOS8DCFUdK"
      },
      "source": [
        "### 전역 최적값 vs 지역 최적값\n",
        "- 초기값이 어니냐에 따라 전체 함수의 최솟값이 될 수도 있고,  \n",
        "  지역적으로 최솟값일 수 있음\n",
        "\n",
        "![](https://www.kdnuggets.com/wp-content/uploads/function-max-global.jpg)\n",
        "<br /><sub>출처: https://www.kdnuggets.com/2017/06/deep-learning-local-minimum.html</sub>\n",
        "\n",
        "$\\quad f_3(x) = x sin(x^2) + 1$ 그래프"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv3mWccFEryk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR80FK0bGba-"
      },
      "source": [
        "#### 전역 최솟값 vs 지역 최솟값 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR2S2zp8Erty"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DsArF9fHpwA"
      },
      "source": [
        "#### 경사하강법 구현(2)\n",
        "- 경사하강을 진행하는 도중, 최솟값에 이르면 경사하강법을 종료하는 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1cgn4Gr_uJI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZWU40x2Mc8X"
      },
      "source": [
        "$f_3(x) = x sin(x^2) + 1$ 그래프\n",
        "- 각 시작점마다 경사하강법으로 내려가다가 최솟값으로 인지하는 부분에서 멈춤 \n",
        "\n",
        "  step_num(반복횟수)만큼 다 돌지 않는 경우도 발생  \n",
        "\n",
        "  하지만 주어진 범위 내에서의 최솟값은 첫번째 시작점일 때이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUJk31aXIH_p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd2g3OL-Efwv"
      },
      "source": [
        "### 학습률(learning rate)\n",
        "- 학습률 값은 적절히 지정해야 한다!\n",
        "- 너무 크면 발산하고, 너무 작으면 학습이 잘 되지 않는다.\n",
        "  \n",
        "![](https://cdn-images-1.medium.com/freeze/max/1000/1*22oh44C5tUHbZ0yvIKWDFg.png)\n",
        "<sub>출처: https://mc.ai/an-introduction-to-gradient-descent-algorithm/</sub>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwi3xvcdEg-f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXFkHxVvTX8T"
      },
      "source": [
        "#### 학습률별 경사하강법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhdS_6RmTXTu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMFZIwN7Ehty"
      },
      "source": [
        "### 안장점(Saddle Point)\n",
        "\n",
        "- 기울기가 0이지만 극값이 되지 않음\n",
        "- 경사하강법은 안장점에서 벗어나지 못함\n",
        "\n",
        "![](https://e7.pngegg.com/pngimages/413/127/png-clipart-saddle-point-graph-of-a-function-gradient-descent-deep-learning-mathematics-mathematics-angle-furniture-thumbnail.png)\n",
        "<br /><sub>출처: https://www.pngegg.com/en/png-czdxs</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRsj9SgHIG_1"
      },
      "source": [
        "$f_2(x) = 0.01x^4 - 0.3x^3 - 1.0x + 10.0$ 그래프로 확인하기\n",
        "\n",
        "- 첫번째 시작점  \n",
        "  - count가 100, 즉 step_num(반복횟수)만큼 루프를 돌았음에도  \n",
        "  손실함수의 값이 10 언저리에서 멈춤. 변화 X\n",
        "  - 안장점 (Saddle Point)\n",
        "  \n",
        "  - 이는 학습률(learning rate)조절 또는 다른 초기값 설정을 통해 수정해야함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML3HRPB2IHeF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59zUn7KsURUI"
      },
      "source": [
        "$f_3(x) = x sin(x^2) + 1$ 그래프에서 확인하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ExtoNteEiFx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}